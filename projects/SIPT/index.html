
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Structure Inducing Pre-Training - Zitnik Lab</title>
    <link rel="stylesheet" href="/assets/css/app.css">
    <link rel="shortcut icon" type="image/png"
           href="/favicon.png" 
    />
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Structure Inducing Pre-Training | Zitnik Lab</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Structure Inducing Pre-Training" />
<meta name="author" content="Marinka Zitnik" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Pre-training, language models, foundation models, artificial intelligence, machine learning" />
<meta property="og:description" content="Pre-training, language models, foundation models, artificial intelligence, machine learning" />
<link rel="canonical" href="https://zitniklab.hms.harvard.edu/projects/SIPT/" />
<meta property="og:url" content="https://zitniklab.hms.harvard.edu/projects/SIPT/" />
<meta property="og:site_name" content="Zitnik Lab" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Structure Inducing Pre-Training" />
<meta name="twitter:site" content="@marinkazitnik" />
<meta name="twitter:creator" content="@Marinka Zitnik" />
<script type="application/ld+json">
{"url":"https://zitniklab.hms.harvard.edu/projects/SIPT/","author":{"@type":"Person","name":"Marinka Zitnik"},"headline":"Structure Inducing Pre-Training","description":"Pre-training, language models, foundation models, artificial intelligence, machine learning","@type":"WebPage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-162129505-1"></script>
<script>
  window['ga-disable-UA-162129505-1'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-162129505-1');
</script><!-- head scripts --></head>

  <body>
    
<nav class="navbar is-primary" >
    <div class="container">
        <div class="navbar-brand">
            <a href="/" class="navbar-item"><b>
                Zitnik Lab
            </b></a>
            <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu">
            <div class="navbar-start">
<!--                <a href="/" class="navbar-item "><b>Home</b></a>-->
                
                
                    
                    <div class="navbar-item has-dropdown is-hoverable">
                        <a href="/#" class="navbar-link "><b>About</b></a>
                        <div class="navbar-dropdown">
                            
                            <a href="/bio/" class="navbar-item "><b>Bio</b></a>
                            
                            <a href="/contact/" class="navbar-item "><b>Contact</b></a>
                            
                            <a href="/talks/" class="navbar-item "><b>Recent Talks</b></a>
                            
                        </div>
                    </div>
                    
                
                    
                <a href="/research/" class="navbar-item "><b>Research</b></a>
                    
                
                    
                <a href="/publications/" class="navbar-item "><b>Publications</b></a>
                    
                
                    
                <a href="/people/" class="navbar-item "><b>Members</b></a>
                    
                
                    
                <a href="/meetings/" class="navbar-item "><b>Education</b></a>
                    
                
                    
                <a href="/DMAI/" class="navbar-item "><b>DMAI</b></a>
                    
                
                    
                <a href="/data/" class="navbar-item "><b>Datasets</b></a>
                    
                
                    
                <a href="/software/" class="navbar-item "><b>AI Models</b></a>
                    
                
                    
                <a href="https://zitniklab.hms.harvard.edu/TDC/" class="navbar-item "><b>TDC</b></a>
                    
                
                    
                <a href="/news/" class="navbar-item "><b>News</b></a>
                    
                
                    
                <a href="/jobs/" class="navbar-item "><b>Join Us</b></a>
                    
                
                
            </div>
        </div>
    </div>
</nav>

    
        <section class="hero  is-medium  is-bold is-primary"  style="background: url('/hero.jpg') no-repeat center center; background-size: cover;" >
    <div class="hero-body">
        <div class="container">
            <p class="title is-2">Structure Inducing Pre-Training</p>
            <p class="subtitle is-3"></p>
            
        </div>
    </div>
</section>
    
    


    <section class="section">
        <div class="container">
            <div class="columns">
                
                <div class="column is-8">
                    
                    
                    
<div class="content">
    <div class="box has-background-info has-text-white">
<p>
Language model pre-training and derived methods are incredibly impactful in machine learning. However, there remains considerable uncertainty on exactly why pre-training helps improve performance for fine-tuning tasks. This is especially true when attempting to adapt
language-model pre-training to domains outside of natural language. We analyze this problem by exploring how existing pre-training methods impose relational structure in their induced per-sample latent spaces—i.e., what constraints do pre-training methods impose on the distance or geometry between the pre-trained embeddings of two samples x<sub>i</sub> and x<sub>j</sub>.
</p>
<p>
Through a comprehensive review of existing pre-training methods, we find that this question remains open. This is true despite theoretical analyses demonstrating the importance of understanding this form of induced structure. Based on this review, we introduce a descriptive framework for pre-training that allows for a granular, comprehensive understanding of how relational structure can be induced. 
</p>
<p>
We present a theoretical analysis of this framework from the first principles and establish a connection between the relational inductive bias of pre-training and fine-tuning performance. We also show how to use the framework to define new pre-training methods. Finally, we build upon these findings with empirical studies on benchmarks spanning 3 data modalities and ten fine-tuning tasks. These experiments validate our theoretical analyses, inform the design of novel pre-training methods, and establish consistent improvements over a compelling suite of baseline methods.
</p>
</div>

<h2 id="existing-pre-training-pt-methods">Existing Pre-training (PT) Methods</h2>

<p>Our review summarized 71 existing natural language processing (NLP) and NLP-derived PT methods, which are categorized into clusters based on how they impose structural constraints over the PT per sample) latent space. Clusters are arranged on axes via manual judgments on whether the imposed constraint is shallow vs. deep and implicit vs. explicit. Clusters are sized such that the area corresponds to the number of citations methods included in that cluster have received on average per month since first publication, according to Google Scholar’s citation count. In the following figure, “None” captures models that leverage no pre-training loss over the per-sample embedding. “NSP” refers to “Next sentence Prediction,” the per-sample PT task introduced in BERT. “SOP” refers to “Sentence-order Prediction,” the per-sample PT task introduced in ALBERT. Note that over 90 studies in total were considered in our review, but only 71 met the inclusion criteria to be included in this figure. These methods are described in more detail in the manuscript.</p>

<center>
<img src="/img/SIPT-review.png" />
</center>

<h2 id="per-sample-vs-per-token-latent-space">Per-sample vs. Per-token Latent Space</h2>

<p>Language model pre-training methods produce both per-sample and per-token latent spaces. Illustrated below via the RoBERTa model are traditional language modeling objectives, which use only a masked language model loss during pre-training) only constrain the per-token latent space.</p>

<center>
<img src="/img/SIPT-RoBERTa.png" />
</center>

<h2 id="structure-inducing-pre-training">Structure Inducing Pre-Training</h2>

<p>We re-cast the PT formulation by taking a pre-training graph G<sub>PT</sub> as an auxiliary input. G<sub>PT</sub> is used to define a new structure-inducing objective L<sub>SI</sub>, which pushes a pre-training encoder f<sub>θ</sub> to embed samples such that samples are close in the latent space if and only if they are linked in G<sub>PT</sub>.</p>

<center>
<img src="/img/SIPT-overview.png" />
</center>

<h2 id="publication">Publication</h2>

<p><a href="https://www.nature.com/articles/s42256-023-00647-z">Structure Inducing Pre-Training</a><br />
Matthew B.A. McDermott, Brendan Yap, Peter Szolovits and Marinka Zitnik<br />
<em>Nature Machine Intelligence</em> 2023 <a href="https://arxiv.org/abs/2103.10334">[arXiv]</a></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{mcdermott2023structure,
  title={Structure Inducing Pre-Training},
  author={McDermott, Matthew and Yap, Brendan and Szolovits, Peter and Zitnik, Marinka},
  journal={Nature Machine Intelligence},
  year={2023},
  publisher={Nature Springer Group}
}
</code></pre></div></div>

<h2 id="code">Code</h2>

<p>PyTorch implementation together with documentation and examples of usage is available in the <a href="https://github.com/mmcdermott/structure_inducing_pre-training">GitHub repository</a>.</p>

<h2 id="supplementary-information">Supplementary Information</h2>

<p>Review of language model pre-training methods, Supplementary Figures 1–3 and Table 1 are available at <a href="https://www.nature.com/articles/s42256-023-00647-z#Sec26">Nature Machine Intelligence.</a></p>

<h2 id="authors">Authors</h2>

<ul>
  <li><a href="https://scholar.google.com/citations?user=_V96PXoAAAAJ&amp;hl=en">Matthew B. A. McDermott</a></li>
  <li><a href="">Brendan Yap</a></li>
  <li><a href="https://groups.csail.mit.edu/medg/people/psz/home/Pete_MEDG_site/Home.html">Peter Szolovits</a></li>
  <li><a href="https://zitniklab.hms.harvard.edu/">Marinka Zitnik</a></li>
</ul>

</div>
                </div>
                
                <div class="column is-4-desktop is-12-tablet">
                    <p class="title is-4">Latest News</p>

<div class="columns is-multiline">
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/12/16/ProCyon/">Foundation Model for Protein Phenotypes</a>-->
        <p class="card-header-title">Dec 2024: &nbsp; <span class="has-text-primary">Foundation Model for Protein Phenotypes</span></p>
<!--        <p class="card-header-item">Dec 2024</p>-->
<!--        <p class="card-footer-item">Dec 16, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>New paper: <a href="https://www.biorxiv.org/content/10.1101/2024.12.10.627665v1">ProCyon is a groundbreaking foundation model for modeling, generating, and predicting protein phenotypes</a>. <a href="https://zitniklab.hms.harvard.edu/ProCyon/">[Project website]</a> <a href="https://github.com/mims-harvard/ProCyon">[Code]</a></p>
</p>-->
            <p>New paper: <a href="https://www.biorxiv.org/content/10.1101/2024.12.10.627665v1">ProCyon is a groundbreaking foundation model for modeling, generating, and predicting protein phenotypes</a>. <a href="https://zitniklab.hms.harvard.edu/ProCyon/">[Project website]</a> <a href="https://github.com/mims-harvard/ProCyon">[Code]</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/12/16/ProCyon/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Dec 16, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/12/07/UnifiedClinicalVocabularyEmbeddings/">Unified Clinical Vocabulary Embeddings</a>-->
        <p class="card-header-title">Dec 2024: &nbsp; <span class="has-text-primary">Unified Clinical Vocabulary Embeddings</span></p>
<!--        <p class="card-header-item">Dec 2024</p>-->
<!--        <p class="card-footer-item">Dec 7, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>New paper: <a href="https://www.medrxiv.org/content/10.1101/2024.12.03.24318322">A unified resource provides a new representation of clinical knowledge by unifying medical vocabularies.</a> (1) Phenotype risk score analysis across 4.57 million patients, (2) Inter-institutional clinician panels evaluate alignment with clinical knowledge across 90 diseases and 3,000 clinical codes.</p>
</p>-->
            <p>New paper: <a href="https://www.medrxiv.org/content/10.1101/2024.12.03.24318322">A unified resource provides a new representation of clinical knowledge by unifying medical vocabularies.</a> (1) Phenotype risk score analysis across 4.57 million patients, (2) Inter-institutional clinician panels evaluate alignment with clinical knowledge across 90 diseases and 3,000 clinical codes.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/12/07/UnifiedClinicalVocabularyEmbeddings/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Dec 7, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/12/07/SPECTRA/">SPECTRA in Nature Machine Intelligence</a>-->
        <p class="card-header-title">Dec 2024: &nbsp; <span class="has-text-primary">SPECTRA in Nature Machine Intelligence</span></p>
<!--        <p class="card-header-item">Dec 2024</p>-->
<!--        <p class="card-footer-item">Dec 7, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>Are biomedical AI models truly as smart as they seem? <a href="https://www.nature.com/articles/s42256-024-00931-6">SPECTRA is a framework that evaluates models by considering the full spectrum of cross-split overlap: train-test similarity.</a> SPECTRA reveals gaps in benchmarks for molecular sequence data across 19 models, including LLMs, GNNs, diffusion models, and conv nets.</p>
</p>-->
            <p>Are biomedical AI models truly as smart as they seem? <a href="https://www.nature.com/articles/s42256-024-00931-6">SPECTRA is a framework that evaluates models by considering the full spectrum of cross-split overlap: train-test similarity.</a> SPECTRA reveals gaps in benchmarks for molecular sequence data across 19 models, including LLMs, GNNs, diffusion models, and conv nets.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/12/07/SPECTRA/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Dec 7, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/11/17/RhodesScholar/">Ayush Noori Selected as a Rhodes Scholar</a>-->
        <p class="card-header-title">Nov 2024: &nbsp; <span class="has-text-primary">Ayush Noori Selected as a Rhodes Scholar</span></p>
<!--        <p class="card-header-item">Nov 2024</p>-->
<!--        <p class="card-footer-item">Nov 17, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>Congratulations to <a href="https://www.thecrimson.com/article/2024/11/18/rhodes-scholars-announced-harvard-students/">Ayush Noori on being named a Rhodes Scholar</a>! Such an incredible achievement!</p>
</p>-->
            <p>Congratulations to <a href="https://www.thecrimson.com/article/2024/11/18/rhodes-scholars-announced-harvard-students/">Ayush Noori on being named a Rhodes Scholar</a>! Such an incredible achievement!</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/11/17/RhodesScholar/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Nov 17, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/11/15/PocketGen/">PocketGen in Nature Machine Intelligence</a>-->
        <p class="card-header-title">Nov 2024: &nbsp; <span class="has-text-primary">PocketGen in Nature Machine Intelligence</span></p>
<!--        <p class="card-header-item">Nov 2024</p>-->
<!--        <p class="card-footer-item">Nov 15, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>PocketGen is a <a href="https://www.nature.com/articles/s42256-024-00920-9">multimodal sequence-structure generative model for designing full-atom ligand-binding protein pockets.</a></p>
</p>-->
            <p>PocketGen is a <a href="https://www.nature.com/articles/s42256-024-00920-9">multimodal sequence-structure generative model for designing full-atom ligand-binding protein pockets.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/11/15/PocketGen/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Nov 15, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/11/01/AIScientist/">Biomedical AI Agents in Cell</a>-->
        <p class="card-header-title">Nov 2024: &nbsp; <span class="has-text-primary">Biomedical AI Agents in Cell</span></p>
<!--        <p class="card-header-item">Nov 2024</p>-->
<!--        <p class="card-footer-item">Nov 1, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>We envision “AI scientists” as <a href="https://www.cell.com/cell/fulltext/S0092-8674(24)01070-5">AI agents capable of skeptical learning and reasoning that empower biomedical research by integrating ML models and biomedical tools with experimental platforms.</a></p>
</p>-->
            <p>We envision “AI scientists” as <a href="https://www.cell.com/cell/fulltext/S0092-8674(24)01070-5">AI agents capable of skeptical learning and reasoning that empower biomedical research by integrating ML models and biomedical tools with experimental platforms.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/11/01/AIScientist/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Nov 1, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/10/19/ACAnet/">Activity Cliffs in Molecular Properties</a>-->
        <p class="card-header-title">Oct 2024: &nbsp; <span class="has-text-primary">Activity Cliffs in Molecular Properties</span></p>
<!--        <p class="card-header-item">Oct 2024</p>-->
<!--        <p class="card-footer-item">Oct 19, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>New paper on <a href="https://chemrxiv.org/engage/chemrxiv/article-details/6470c963be16ad5c57f5526c">activity-cliff informed contrastive learning for molecular property prediction.</a></p>
</p>-->
            <p>New paper on <a href="https://chemrxiv.org/engage/chemrxiv/article-details/6470c963be16ad5c57f5526c">activity-cliff informed contrastive learning for molecular property prediction.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/10/19/ACAnet/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Oct 19, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/10/09/KGARevion/">Knowledge Graph Agent for Medical Reasoning</a>-->
        <p class="card-header-title">Oct 2024: &nbsp; <span class="has-text-primary">Knowledge Graph Agent for Medical Reasoning</span></p>
<!--        <p class="card-header-item">Oct 2024</p>-->
<!--        <p class="card-footer-item">Oct 9, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>New paper introducing a <a href="https://arxiv.org/abs/2410.04660">knowledge graph agent for complex, knowledge-intensive medical reasoning.</a></p>
</p>-->
            <p>New paper introducing a <a href="https://arxiv.org/abs/2410.04660">knowledge graph agent for complex, knowledge-intensive medical reasoning.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/10/09/KGARevion/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Oct 9, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/09/27/NeurIPS2024Papers/">Three Papers Accepted to NeurIPS</a>-->
        <p class="card-header-title">Sep 2024: &nbsp; <span class="has-text-primary">Three Papers Accepted to NeurIPS</span></p>
<!--        <p class="card-header-item">Sep 2024</p>-->
<!--        <p class="card-footer-item">Sep 27, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>Exciting projects include a unified multi-task time series model, a flow-matching approach for generating protein pockets using geometric priors, and a tokenization method that produces invariant molecular representations for integration into large language models.</p>
</p>-->
            <p>Exciting projects include a unified multi-task time series model, a flow-matching approach for generating protein pockets using geometric priors, and a tokenization method that produces invariant molecular representations for integration into large language models.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/09/27/NeurIPS2024Papers/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Sep 27, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/09/25/TxGNNNatureMedicine/">TxGNN Published in Nature Medicine</a>-->
        <p class="card-header-title">Sep 2024: &nbsp; <span class="has-text-primary">TxGNN Published in Nature Medicine</span></p>
<!--        <p class="card-header-item">Sep 2024</p>-->
<!--        <p class="card-footer-item">Sep 25, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>Graph foundation model for drug repurposing published in <a href="https://www.nature.com/articles/s41591-024-03233-x">Nature Medicine</a>. <a href="https://news.harvard.edu/gazette/story/2024/09/using-ai-to-repurpose-existing-drugs-for-treatment-of-rare-diseases/">[Harvard Gazette]</a> <a href="https://hms.harvard.edu/news/researchers-harness-ai-repurpose-existing-drugs-treatment-rare-diseases">[Harvard Medicine News]</a> <a href="https://www.forbes.com/sites/greglicholai/2024/09/26/ai-tool-speeds-drug-repurposing-and-its-free/">[Forbes]</a> <a href="https://developer.nvidia.com/blog/ai-uses-zero-shot-learning-to-find-existing-drugs-for-treating-rare-diseases/">[NVIDIA]</a> <a href="https://kempnerinstitute.harvard.edu/news/txgnn-ai-dr-house-for-disease-treatment/">[Kempner Institute]</a> <a href="https://www.thecrimson.com/article/2024/10/9/drug-repurposing-ai-model/">[Harvard Crimson]</a></p>
</p>-->
            <p>Graph foundation model for drug repurposing published in <a href="https://www.nature.com/articles/s41591-024-03233-x">Nature Medicine</a>. <a href="https://news.harvard.edu/gazette/story/2024/09/using-ai-to-repurpose-existing-drugs-for-treatment-of-rare-diseases/">[Harvard Gazette]</a> <a href="https://hms.harvard.edu/news/researchers-harness-ai-repurpose-existing-drugs-treatment-rare-diseases">[Harvard Medicine News]</a> <a href="https://www.forbes.com/sites/greglicholai/2024/09/26/ai-tool-speeds-drug-repurposing-and-its-free/">[Forbes]</a> <a href="https://developer.nvidia.com/blog/ai-uses-zero-shot-learning-to-find-existing-drugs-for-treating-rare-diseases/">[NVIDIA]</a> <a href="https://kempnerinstitute.harvard.edu/news/txgnn-ai-dr-house-for-disease-treatment/">[Kempner Institute]</a> <a href="https://www.thecrimson.com/article/2024/10/9/drug-repurposing-ai-model/">[Harvard Crimson]</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/09/25/TxGNNNatureMedicine/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Sep 25, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/08/28/GraphAI/">Graph AI in Medicine</a>-->
        <p class="card-header-title">Aug 2024: &nbsp; <span class="has-text-primary">Graph AI in Medicine</span></p>
<!--        <p class="card-header-item">Aug 2024</p>-->
<!--        <p class="card-footer-item">Aug 28, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>Excited to share a new perspective on <a href="https://go.shr.lc/4g0KpLV">Graph Artificial Intelligence in Medicine</a> in Annual Reviews.</p>
</p>-->
            <p>Excited to share a new perspective on <a href="https://go.shr.lc/4g0KpLV">Graph Artificial Intelligence in Medicine</a> in Annual Reviews.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/08/28/GraphAI/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Aug 28, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/08/15/PINNACLENews/">How Proteins Behave in Context</a>-->
        <p class="card-header-title">Aug 2024: &nbsp; <span class="has-text-primary">How Proteins Behave in Context</span></p>
<!--        <p class="card-header-item">Aug 2024</p>-->
<!--        <p class="card-footer-item">Aug 15, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p><a href="https://hms.harvard.edu/news/new-ai-tool-captures-how-proteins-behave-context">Harvard Medicine News</a> on our new AI tool that captures how proteins behave in context. <a href="https://kempnerinstitute.harvard.edu/research/deeper-learning/context-matters-for-foundation-models-in-biology/">Kempner Institute</a> on how context matters for foundation models in biology.</p>
</p>-->
            <p><a href="https://hms.harvard.edu/news/new-ai-tool-captures-how-proteins-behave-context">Harvard Medicine News</a> on our new AI tool that captures how proteins behave in context. <a href="https://kempnerinstitute.harvard.edu/research/deeper-learning/context-matters-for-foundation-models-in-biology/">Kempner Institute</a> on how context matters for foundation models in biology.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/08/15/PINNACLENews/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Aug 15, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/07/27/PINNACLENatureMethods/">PINNACLE in Nature Methods</a>-->
        <p class="card-header-title">Jul 2024: &nbsp; <span class="has-text-primary">PINNACLE in Nature Methods</span></p>
<!--        <p class="card-header-item">Jul 2024</p>-->
<!--        <p class="card-footer-item">Jul 27, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>PINNACLE contextual AI model is published in Nature Methods. <a href="https://www.nature.com/articles/s41592-024-02341-3">Paper.</a> <a href="https://www.nature.com/articles/s41592-024-02342-2">Research Briefing.</a> <a href="https://zitniklab.hms.harvard.edu/projects/PINNACLE/">Project website.</a></p>
</p>-->
            <p>PINNACLE contextual AI model is published in Nature Methods. <a href="https://www.nature.com/articles/s41592-024-02341-3">Paper.</a> <a href="https://www.nature.com/articles/s41592-024-02342-2">Research Briefing.</a> <a href="https://zitniklab.hms.harvard.edu/projects/PINNACLE/">Project website.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/07/27/PINNACLENatureMethods/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Jul 27, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/07/15/DigitalTwins/">Digital Twins as Global Health and Disease Models of Individuals</a>-->
        <p class="card-header-title">Jul 2024: &nbsp; <span class="has-text-primary">Digital Twins as Global Health and Disease Models of Individuals</span></p>
<!--        <p class="card-header-item">Jul 2024</p>-->
<!--        <p class="card-footer-item">Jul 15, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p><a href="https://www.preprints.org/manuscript/202406.0357/">Paper on digitial twins</a> outlining strategies to leverage molecular and computational techniques to construct dynamic digital twins on the scale of populations to individuals.</p>
</p>-->
            <p><a href="https://www.preprints.org/manuscript/202406.0357/">Paper on digitial twins</a> outlining strategies to leverage molecular and computational techniques to construct dynamic digital twins on the scale of populations to individuals.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/07/15/DigitalTwins/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Jul 15, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/07/14/GraphAdversarialDiffusion/">Graph Diffusion Convolutions at ICML</a>-->
        <p class="card-header-title">Jul 2024: &nbsp; <span class="has-text-primary">Graph Diffusion Convolutions at ICML</span></p>
<!--        <p class="card-header-item">Jul 2024</p>-->
<!--        <p class="card-footer-item">Jul 14, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p><a href="https://arxiv.org/abs/2406.02059">Graph diffusion convolution is a geometric deep learning architecture that aggregates information from higher-order network neighbors through a generalized graph diffusion</a> to enhance model robustness to noisy and incomplete datasets. <a href="https://arxiv.org/abs/2406.02059">Paper at ICML.</a></p>
</p>-->
            <p><a href="https://arxiv.org/abs/2406.02059">Graph diffusion convolution is a geometric deep learning architecture that aggregates information from higher-order network neighbors through a generalized graph diffusion</a> to enhance model robustness to noisy and incomplete datasets. <a href="https://arxiv.org/abs/2406.02059">Paper at ICML.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/07/14/GraphAdversarialDiffusion/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Jul 14, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/07/13/TrialBenchLLM3DStructure/">Three Papers: TrialBench, 3D Structure Design, LLM Editing</a>-->
        <p class="card-header-title">Jul 2024: &nbsp; <span class="has-text-primary">Three Papers: TrialBench, 3D Structure Design, LLM Editing</span></p>
<!--        <p class="card-header-item">Jul 2024</p>-->
<!--        <p class="card-footer-item">Jul 13, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>New papers on <a href="https://arxiv.org/abs/2407.00631">TrialBench with AI-ready clinical trial datasets</a>, <a href="https://arxiv.org/abs/2406.03403">structure-based drug design benchmark</a>, and <a href="https://arxiv.org/abs/2407.06483">composable interventions for language models</a>.</p>
</p>-->
            <p>New papers on <a href="https://arxiv.org/abs/2407.00631">TrialBench with AI-ready clinical trial datasets</a>, <a href="https://arxiv.org/abs/2406.03403">structure-based drug design benchmark</a>, and <a href="https://arxiv.org/abs/2407.06483">composable interventions for language models</a>.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/07/13/TrialBenchLLM3DStructure/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Jul 13, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/06/23/TDC2/">TDC-2: Multimodal Foundation for Therapeutics</a>-->
        <p class="card-header-title">Jun 2024: &nbsp; <span class="has-text-primary">TDC-2: Multimodal Foundation for Therapeutics</span></p>
<!--        <p class="card-header-item">Jun 2024</p>-->
<!--        <p class="card-footer-item">Jun 23, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p><a href="https://tdcommons.ai/">The Commons 2.0 (TDC-2)</a> is an overhaul of Therapeutic Data Commons to catalyze research in multimodal models for drug discovery by unifying single-cell biology of diseases, biochemistry of molecules, and effects of drugs through multimodal datasets, AI-powered API endpoints, new tasks and benchmarks. <a href="https://www.biorxiv.org/content/10.1101/2024.06.12.598655v2">Our paper.</a></p>
</p>-->
            <p><a href="https://tdcommons.ai/">The Commons 2.0 (TDC-2)</a> is an overhaul of Therapeutic Data Commons to catalyze research in multimodal models for drug discovery by unifying single-cell biology of diseases, biochemistry of molecules, and effects of drugs through multimodal datasets, AI-powered API endpoints, new tasks and benchmarks. <a href="https://www.biorxiv.org/content/10.1101/2024.06.12.598655v2">Our paper.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/06/23/TDC2/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Jun 23, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/05/29/BroadMIA/">Broad MIA: Protein Language Models</a>-->
        <p class="card-header-title">May 2024: &nbsp; <span class="has-text-primary">Broad MIA: Protein Language Models</span></p>
<!--        <p class="card-header-item">May 2024</p>-->
<!--        <p class="card-footer-item">May 29, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>Check out our Broad’s seminars on <a href="https://youtu.be/LcLmvtXHI1s?si=GABqGdFt5ze9leT_">Multimodal protein language models for deciphering protein function.</a></p>
</p>-->
            <p>Check out our Broad’s seminars on <a href="https://youtu.be/LcLmvtXHI1s?si=GABqGdFt5ze9leT_">Multimodal protein language models for deciphering protein function.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/05/29/BroadMIA/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: May 29, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/05/28/KnowingAGene/">On Knowing a Gene in Cell Systems</a>-->
        <p class="card-header-title">May 2024: &nbsp; <span class="has-text-primary">On Knowing a Gene in Cell Systems</span></p>
<!--        <p class="card-header-item">May 2024</p>-->
<!--        <p class="card-footer-item">May 28, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>We shed light on <a href="https://www.sciencedirect.com/science/article/pii/S2405471224001236">distributional gene representations and their potential applications in biology to characterize gene function from a broader and more holistic perspective.</a></p>
</p>-->
            <p>We shed light on <a href="https://www.sciencedirect.com/science/article/pii/S2405471224001236">distributional gene representations and their potential applications in biology to characterize gene function from a broader and more holistic perspective.</a></p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/05/28/KnowingAGene/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: May 28, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    
    <div class="column is-12">
        <div class="card">
    
    <header class="card-header">
<!--        <a class="card-header-title" href="/2024/04/04/BIomedicalAIAgents/">Biomedical AI Agents</a>-->
        <p class="card-header-title">Apr 2024: &nbsp; <span class="has-text-primary">Biomedical AI Agents</span></p>
<!--        <p class="card-header-item">Apr 2024</p>-->
<!--        <p class="card-footer-item">Apr 4, 2024</p>-->
    </header>
    
    <div class="card-content">
<!--        <div class="content">-->
<!--            -->
<!--            <p><p>We envision <a href="https://arxiv.org/abs/2404.02831">‘AI scientists’ as systems capable of skeptical learning and reasoning that empower biomedical research through collaborative agents</a> that integrate machine learning tools with experimental platforms.</p>
</p>-->
            <p>We envision <a href="https://arxiv.org/abs/2404.02831">‘AI scientists’ as systems capable of skeptical learning and reasoning that empower biomedical research through collaborative agents</a> that integrate machine learning tools with experimental platforms.</p>

<!--        </div>-->
<!--        <div class="has-text-centered">-->
<!--            <a href="/2024/04/04/BIomedicalAIAgents/" class="button is-primary">Read more</a>-->
<!--        </div>-->
    </div>
<!--    <footer class="card-footer">-->
<!--        <p class="card-footer-item">Published: Apr 4, 2024</p>-->
<!--    </footer>-->
</div>
    </div>
    

    <div class="column is-12">
        <div class="card">
            <header class="card-header">
        <!--        <a class="card-header-title" href=""></a>-->
            <p class="card-header-title"><span class="has-text-primary">Tweets</span></p>
        <!--        <p class="card-header-item"></p>-->
        <!--        <p class="card-footer-item"></p>-->
            </header>
        <div class="card-content">
        <!--        <div class="content">-->
        <!--            -->
        <!--            <p></p>-->
        <a class="twitter-timeline" data-width="500" data-height="500" data-theme="light" href="https://twitter.com/marinkazitnik?ref_src=twsrc%5Etfw" data-chrome="noheader transparent nofooter nofooter noborders">Tweets by marinkazitnik</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
        <!--        </div>-->
        <!--        <div class="has-text-centered">-->
        <!--            <a href="" class="button is-primary">Read more</a>-->
        <!--        </div>-->
            </div>
        </div>
    </div>
</div>




                </div>
                
            </div>
        </div>
    </section>
    
    <script src="/assets/js/app.js" type="text/javascript"></script><!-- footer scripts -->
<div style="background-color:#A41034">
        <div class="content is-normal has-text-centered">
            <p style="color:white;padding-top:20px;padding-bottom:20px;"><a href="https://scholar.harvard.edu/marinka" style="color:white"><b>Zitnik Lab</b></a>
                &nbsp;&middot;&nbsp; <a href="#" style="color:white"><b>Artificial Intelligence in Medicine and Science</b></a>
                &nbsp;&middot;&nbsp; <a href="https://harvard.edu" style="color:white"><b>Harvard</b></a>
                &nbsp;&middot;&nbsp; <a href="https://dbmi.hms.harvard.edu/" style="color:white"><b>Department of Biomedical Informatics</b></a></p>
        </div>
</div></body>
</html>

